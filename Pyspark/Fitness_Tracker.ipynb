{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6452eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc9aece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyspark_args_str = \"\"\n",
    "pyspark_args_str += '--packages \"io.delta:delta-core_2.12:1.0.0\" '\n",
    "pyspark_args_str += '--conf \"spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension\" '\n",
    "pyspark_args_str += '--conf \"spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog\" '\n",
    "pyspark_args_str += 'pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbea120e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'--packages \"io.delta:delta-core_2.12:1.0.0\" --conf \"spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension\" --conf \"spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog\" pyspark-shell'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark_args_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90c85977",
   "metadata": {},
   "outputs": [],
   "source": [
    "environ['PYSPARK_SUBMIT_ARGS'] = pyspark_args_str\n",
    "  \n",
    "from pyspark import sql\n",
    "\n",
    "spark = sql.SparkSession.builder \\\n",
    "        .master(\"local[8]\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "\n",
    "def display(dataframe):\n",
    "    return dataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dc1bdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://0de229944277:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f052cc3e1c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19811a69",
   "metadata": {},
   "source": [
    "#### 1. Import Jan 2020 - May 2020 & late Feb 2020 data from S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f07597b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "from urllib.request import urlretrieve\n",
    "import time\n",
    "\n",
    "BASE_URL = \"https://hadoop-and-big-data.s3-us-west-2.amazonaws.com/fitness-tracker/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d3a77d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_file_handles(year: int, month: int, filePath: str, is_late: bool):\n",
    "    \"\"\"\n",
    "    if the file is late, add late to the end of the file path name, if not, return the file & filepath\n",
    "    \"\"\"\n",
    "    late = \"\"\n",
    "    if is_late:\n",
    "        late = \"_late\"\n",
    "    file = f\"health_tracker_data_{year}_{month}{late}.json\"\n",
    "    \n",
    "    dbfsPath = \"\"\n",
    "    if is_late:\n",
    "        dbfsPath += \"late/\"\n",
    "    filePath += file\n",
    "\n",
    "    return file, filePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98e0e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(year: int, month: int, filePath: str, is_late: bool = False) -> bool:\n",
    "    file, filePath = _generate_file_handles(year, month, filePath, is_late)\n",
    "    uri = BASE_URL + file\n",
    "\n",
    "    urlretrieve(uri, filePath)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b1ddb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness_Tracker.ipynb                 health_tracker_data_2020_4.json\r\n",
      "health_tracker_data_2020_1.json       health_tracker_data_2020_5.json\r\n",
      "health_tracker_data_2020_2.json       \u001b[0m\u001b[01;34mlate\u001b[0m/\r\n",
      "health_tracker_data_2020_2_late.json  latehealth_tracker_data_2020_2_late.json\r\n",
      "health_tracker_data_2020_3.json       S3_Spark_Notes.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "348d2584",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jan_df = spark.read.json(\"health_tracker_data_2020_1.json\")\n",
    "feb_df = spark.read.json(\"health_tracker_data_2020_2.json\")\n",
    "mar_df = spark.read.json(\"health_tracker_data_2020_3.json\")\n",
    "apr_df = spark.read.json(\"health_tracker_data_2020_4.json\")\n",
    "may_df = spark.read.json(\"health_tracker_data_2020_5.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cff03732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read late json file\n",
    "feb_late_df = spark.read.json(\"latehealth_tracker_data_2020_2_late.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f1f51262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+--------------+-----------+\n",
      "|device_id|    heartrate|          name|       time|\n",
      "+---------+-------------+--------------+-----------+\n",
      "|        0|52.8139067501|Deborah Powell|1.5778368E9|\n",
      "+---------+-------------+--------------+-----------+\n",
      "only showing top 1 row\n",
      "\n",
      "+---------+-------------+--------------+-----------+\n",
      "|device_id|    heartrate|          name|       time|\n",
      "+---------+-------------+--------------+-----------+\n",
      "|        0|62.2867126811|Deborah Powell|1.5805152E9|\n",
      "+---------+-------------+--------------+-----------+\n",
      "only showing top 1 row\n",
      "\n",
      "+---------+-----------+-------------+--------------+-----------+\n",
      "|device_id|device_type|    heartrate|          name|       time|\n",
      "+---------+-----------+-------------+--------------+-----------+\n",
      "|        0|  version 2|57.6447293596|Deborah Powell|1.5830208E9|\n",
      "+---------+-----------+-------------+--------------+-----------+\n",
      "only showing top 1 row\n",
      "\n",
      "+---------+-----------+------------+--------------+-----------+\n",
      "|device_id|device_type|   heartrate|          name|       time|\n",
      "+---------+-----------+------------+--------------+-----------+\n",
      "|        0|  version 2|62.320653259|Deborah Powell|1.5856992E9|\n",
      "+---------+-----------+------------+--------------+-----------+\n",
      "only showing top 1 row\n",
      "\n",
      "+---------+-----------+-------------+--------------+-----------+\n",
      "|device_id|device_type|    heartrate|          name|       time|\n",
      "+---------+-----------+-------------+--------------+-----------+\n",
      "|        0|  version 2|63.9075968813|Deborah Powell|1.5882912E9|\n",
      "+---------+-----------+-------------+--------------+-----------+\n",
      "only showing top 1 row\n",
      "\n",
      "+---------+-------------+---------+-----------+\n",
      "|device_id|    heartrate|     name|       time|\n",
      "+---------+-------------+---------+-----------+\n",
      "|        4|49.7135247158|James Hou|1.5827616E9|\n",
      "+---------+-------------+---------+-----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view column names of dataframes\n",
    "jan_df.show(1)\n",
    "feb_df.show(1)\n",
    "mar_df.show(1)\n",
    "apr_df.show(1)\n",
    "may_df.show(1)\n",
    "feb_late_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "756ade18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "# add device_type column to jan 2020 data\n",
    "jan_new_df = jan_df.withColumn('device_type', lit('null'))\n",
    "jan_new_df = jan_new_df.select('device_id','device_type','heartrate', 'name', 'time' )\n",
    "\n",
    "# add device_type column to feb 2020 data \n",
    "feb_new_df = feb_df.withColumn('device_type', lit('null'))\n",
    "feb_new_df = feb_new_df.select('device_id','device_type','heartrate', 'name', 'time' )\n",
    "\n",
    "# add device_type column to feb_late 2020 data\n",
    "feb_late_new_df = feb_late_df.withColumn('device_type', lit('null'))\n",
    "feb_late_new_df = feb_late_new_df.select('device_id','device_type','heartrate', 'name', 'time' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "12775b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "df_list = [jan_new_df, feb_new_df, feb_late_new_df, mar_df, apr_df, may_df]\n",
    "df = reduce(DataFrame.unionAll, df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f13dde01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import types as t\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b13ab0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------------+--------------+-----------+-------------------+-----+\n",
      "|device_id|device_type|    heartrate|          name|       time|          timestamp|month|\n",
      "+---------+-----------+-------------+--------------+-----------+-------------------+-----+\n",
      "|        0|       null|52.8139067501|Deborah Powell|1.5778368E9|2020-01-01 00:00:00|    1|\n",
      "|        0|       null|53.9078900098|Deborah Powell|1.5778404E9|2020-01-01 01:00:00|    1|\n",
      "+---------+-----------+-------------+--------------+-----------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('timestamp', f.to_timestamp(df['time']))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b5ad7660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------------+--------------+-----------+-------------------+-----+\n",
      "|device_id|device_type|    heartrate|          name|       time|          timestamp|month|\n",
      "+---------+-----------+-------------+--------------+-----------+-------------------+-----+\n",
      "|        0|       null|52.8139067501|Deborah Powell|1.5778368E9|2020-01-01 00:00:00|    1|\n",
      "|        0|       null|53.9078900098|Deborah Powell|1.5778404E9|2020-01-01 01:00:00|    1|\n",
      "+---------+-----------+-------------+--------------+-----------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('month', month(df.timestamp))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3f81cdf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_api() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-200-87259e6d02a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'device_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: _api() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "df.groupBy('month').count('device_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d4eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
