{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "062ba45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93f4d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyspark_args_str = \"\"\n",
    "pyspark_args_str += '--packages \"io.delta:delta-core_2.12:1.0.0\" '\n",
    "pyspark_args_str += '--conf \"spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension\" '\n",
    "pyspark_args_str += '--conf \"spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog\" '\n",
    "pyspark_args_str += 'pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9a3277d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'--packages \"io.delta:delta-core_2.12:1.0.0\" --conf \"spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension\" --conf \"spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog\" pyspark-shell'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark_args_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa152c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "environ['PYSPARK_SUBMIT_ARGS'] = pyspark_args_str\n",
    "  \n",
    "from pyspark import sql\n",
    "\n",
    "spark = sql.SparkSession.builder \\\n",
    "        .master(\"local[8]\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "\n",
    "def display(dataframe):\n",
    "    return dataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edf2735c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://30440d777360:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f19dc92a100>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eb91a5",
   "metadata": {},
   "source": [
    "#### 1. Import Jan 2020 - May 2020 & late Feb 2020 data from the S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e37eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "from urllib.request import urlretrieve\n",
    "import time\n",
    "\n",
    "BASE_URL = \"https://hadoop-and-big-data.s3-us-west-2.amazonaws.com/fitness-tracker/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4012bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_file_handles(year: int, month: int, filePath: str, is_late: bool):\n",
    "    \"\"\"\n",
    "    if the file is late, add late to the end of the file path name, if not, return the file & filepath\n",
    "    \"\"\"\n",
    "    late = \"\"\n",
    "    if is_late:\n",
    "        late = \"_late\"\n",
    "    file = f\"health_tracker_data_{year}_{month}{late}.json\"\n",
    "    \n",
    "    dbfsPath = \"\"\n",
    "    if is_late:\n",
    "        dbfsPath += \"late/\"\n",
    "    filePath += file\n",
    "\n",
    "    return file, filePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39dbb15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(year: int, month: int, filePath: str, is_late: bool = False) -> bool:\n",
    "    file, filePath = _generate_file_handles(year, month, filePath, is_late)\n",
    "    uri = BASE_URL + file\n",
    "\n",
    "    urlretrieve(uri, filePath)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48a0ef86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import january 2020 - may 2020 data\n",
    "retrieve_data(2020, 1, \"data/\")\n",
    "retrieve_data(2020, 2, \"data/\")\n",
    "retrieve_data(2020, 3, \"data/\")\n",
    "retrieve_data(2020, 4, \"data/\")\n",
    "retrieve_data(2020, 5, \"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47a6f27e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import late February 2020 data\n",
    "retrieve_data(2020, 2, \"data/\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b93f87ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "jan_df = spark.read.json(\"data/health_tracker_data_2020_1.json\")\n",
    "feb_df = spark.read.json(\"data/health_tracker_data_2020_2.json\")\n",
    "mar_df = spark.read.json(\"data/health_tracker_data_2020_3.json\")\n",
    "apr_df = spark.read.json(\"data/health_tracker_data_2020_4.json\")\n",
    "may_df = spark.read.json(\"data/health_tracker_data_2020_5.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b9aa027",
   "metadata": {},
   "outputs": [],
   "source": [
    "feb_late_df = spark.read.json(\"data/health_tracker_data_2020_2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb4d9c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "# add device_type column to jan 2020 data\n",
    "jan_new_df = jan_df.withColumn('device_type', lit('null'))\n",
    "jan_new_df = jan_new_df.select('device_id','device_type','heartrate', 'name', 'time' )\n",
    "\n",
    "# add device_type column to feb 2020 data \n",
    "feb_new_df = feb_df.withColumn('device_type', lit('null'))\n",
    "feb_new_df = feb_new_df.select('device_id','device_type','heartrate', 'name', 'time' )\n",
    "\n",
    "# add device_type column to feb_late 2020 data\n",
    "feb_late_new_df = feb_late_df.withColumn('device_type', lit('null'))\n",
    "feb_late_new_df = feb_late_new_df.select('device_id','device_type','heartrate', 'name', 'time' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f12cf8",
   "metadata": {},
   "source": [
    "#### 2. Merge all datasets into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef4e46d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "df_list = [jan_new_df, feb_new_df, feb_late_new_df, mar_df, apr_df, may_df]\n",
    "df = reduce(DataFrame.unionAll, df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4b4ee09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21576"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf5a548d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------------+--------------+-----------+-------------------+\n",
      "|device_id|device_type|    heartrate|          name|       time|          timestamp|\n",
      "+---------+-----------+-------------+--------------+-----------+-------------------+\n",
      "|        0|       null|52.8139067501|Deborah Powell|1.5778368E9|2020-01-01 00:00:00|\n",
      "|        0|       null|53.9078900098|Deborah Powell|1.5778404E9|2020-01-01 01:00:00|\n",
      "+---------+-----------+-------------+--------------+-----------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import types as t\n",
    "import datetime\n",
    "\n",
    "\n",
    "df = df.withColumn('timestamp', f.to_timestamp(df['time']))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c724db0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------------+--------------+-----------+-------------------+-----+\n",
      "|device_id|device_type|    heartrate|          name|       time|          timestamp|month|\n",
      "+---------+-----------+-------------+--------------+-----------+-------------------+-----+\n",
      "|        0|       null|52.8139067501|Deborah Powell|1.5778368E9|2020-01-01 00:00:00|    1|\n",
      "|        0|       null|53.9078900098|Deborah Powell|1.5778404E9|2020-01-01 01:00:00|    1|\n",
      "+---------+-----------+-------------+--------------+-----------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('month', f.month(df.timestamp))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fd4434",
   "metadata": {},
   "source": [
    "#### 3. Taking a closer look at February's data, James Hou is missing data from device 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c7947545",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_feb_list = [feb_new_df, feb_late_new_df]\n",
    "all_feb = reduce(DataFrame.unionAll, all_feb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5d3daa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|device_id|count|\n",
      "+---------+-----+\n",
      "|        0| 4344|\n",
      "|        1| 4344|\n",
      "|        3| 4344|\n",
      "|        2| 4344|\n",
      "|        4| 4200|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby(\"device_id\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8fa08041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-----+\n",
      "|month|device_id|count|\n",
      "+-----+---------+-----+\n",
      "|    3|        3|  744|\n",
      "|    1|        0|  744|\n",
      "|    5|        3|  744|\n",
      "|    5|        4|  744|\n",
      "|    5|        1|  744|\n",
      "|    3|        4|  744|\n",
      "|    4|        2|  720|\n",
      "|    1|        3|  744|\n",
      "|    3|        1|  744|\n",
      "|    2|        2| 1392|\n",
      "|    4|        0|  720|\n",
      "|    1|        4|  744|\n",
      "|    4|        1|  720|\n",
      "|    3|        2|  744|\n",
      "|    2|        4| 1248|\n",
      "|    1|        1|  744|\n",
      "|    2|        1| 1392|\n",
      "|    4|        4|  720|\n",
      "|    3|        0|  744|\n",
      "|    2|        3| 1392|\n",
      "+-----+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby(['month','device_id']).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ed404fa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|device_id|count|\n",
      "+---------+-----+\n",
      "|        0| 1392|\n",
      "|        1| 1392|\n",
      "|        3| 1392|\n",
      "|        2| 1392|\n",
      "|        4| 1248|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_feb.groupBy(\"device_id\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "235d7109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|          name|count|\n",
      "+--------------+-----+\n",
      "|     Sam Knopp| 1392|\n",
      "|     James Hou| 1248|\n",
      "|   Minh Nguyen| 1392|\n",
      "|Kristin Vasser| 1392|\n",
      "|Deborah Powell| 1392|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_feb.groupBy(\"name\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c168ce4",
   "metadata": {},
   "source": [
    "#### Heartrate Analysis: I wanted to look at the heartrate ranges to see if data was ommitted but feb data is consistent with the remainder of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f238de6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+--------------+\n",
      "|device_id|min_heartrate  |max_heartrate |\n",
      "+---------+---------------+--------------+\n",
      "|0        |-395.1306033635|186.4790827731|\n",
      "|1        |-226.4962764909|186.2081869555|\n",
      "|3        |-263.5045292615|218.7730128322|\n",
      "|2        |-323.6580551676|184.7433209566|\n",
      "|4        |-310.6998377211|185.2604814742|\n",
      "+---------+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_feb = df.filter(df['month'] != 2)\n",
    "no_feb.groupBy(\"device_id\") \\\n",
    "    .agg(f.min(\"heartrate\").alias(\"min_heartrate\"), \\\n",
    "         f.max(\"heartrate\").alias(\"max_heartrate\"), \\\n",
    "    ) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d2af891c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+--------------+\n",
      "|device_id|min_heartrate  |max_heartrate |\n",
      "+---------+---------------+--------------+\n",
      "|0        |-218.062685331 |170.8754616576|\n",
      "|1        |-289.9324513412|165.8129031814|\n",
      "|3        |-179.6888893893|175.0032148522|\n",
      "|2        |-190.2847838357|189.2113455089|\n",
      "|4        |-138.2444236427|199.092971234 |\n",
      "+---------+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_feb.groupBy(\"device_id\") \\\n",
    "    .agg(f.min(\"heartrate\").alias(\"min_heartrate\"), \\\n",
    "         f.max(\"heartrate\").alias(\"max_heartrate\"), \\\n",
    "    ) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f818fee5",
   "metadata": {},
   "source": [
    "#### Timestamp Analysis: After taking a more in-depth look at the timestamp data for February, for device 4, there is missing data for the last 3 days of the mont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bb02d43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-------------------+\n",
      "|device_id|min_heartrate      |max_heartrate      |\n",
      "+---------+-------------------+-------------------+\n",
      "|0        |2020-02-01 00:00:00|2020-02-29 23:00:00|\n",
      "|1        |2020-02-01 00:00:00|2020-02-29 23:00:00|\n",
      "|3        |2020-02-01 00:00:00|2020-02-29 23:00:00|\n",
      "|2        |2020-02-01 00:00:00|2020-02-29 23:00:00|\n",
      "|4        |2020-02-01 00:00:00|2020-02-26 23:00:00|\n",
      "+---------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_feb_device_4 = df.filter(df.month == 2)\n",
    "no_feb_device_4.groupBy(\"device_id\") \\\n",
    "    .agg(f.min(\"timestamp\").alias(\"min_heartrate\"), \\\n",
    "         f.max(\"timestamp\").alias(\"max_heartrate\"), \\\n",
    "    ) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6d50b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
